{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d42dba6",
   "metadata": {},
   "source": [
    "# NPM3D PanopticSeg — env stable (Py3.10) + embeddings + éval\n",
    "Ce notebook évite le piège Python 3.12 / Torch 2.x en créant un **environnement Python 3.10** isolé via **micromamba**.\n",
    "On installe les **versions récentes compatibles** avec MinkowskiEngine, puis on suit le pipeline officiel.\n",
    "\n",
    "**Stack choisie (stable et la plus récente compatible ME):**\n",
    "- Python 3.10 (environnement micromamba `npme`)\n",
    "- PyTorch **1.13.1 + cu116**\n",
    "- torch-geometric **2.3.1** (+ roues scatter/sparse/cluster/spline-conv pour 1.13.1+cu116)\n",
    "- MinkowskiEngine **0.5.4** (roues précompilées NVIDIA)\n",
    "\n",
    "Tout ce qui tourne côté Python dans la suite passe par `micromamba run -n npme` pour être sûr qu’on reste dans le bon env."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa97a33",
   "metadata": {},
   "source": [
    "## 0) Vérif GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a89b6aa",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:27:22.846687Z",
     "iopub.status.busy": "2025-09-17T07:27:22.846347Z",
     "iopub.status.idle": "2025-09-17T07:27:23.150733Z",
     "shell.execute_reply": "2025-09-17T07:27:23.139133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: nvidia-smi: not found\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!nvidia-smi || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152f6d3",
   "metadata": {},
   "source": [
    "## 1) Installer micromamba, créer env Py3.10 et installer les libs compatibles ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff1cb66",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:27:23.172661Z",
     "iopub.status.busy": "2025-09-17T07:27:23.171306Z",
     "iopub.status.idle": "2025-09-17T07:32:19.866634Z",
     "shell.execute_reply": "2025-09-17T07:32:19.865056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ export MAMBA_ROOT_PREFIX=/content/micromamba\n",
      "+ MAMBA_ROOT_PREFIX=/content/micromamba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ '[' '!' -d /content/micromamba ']'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba env list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ grep -q '^npme'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba run -n npme python -m pip install --upgrade pip wheel setuptools packaging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /content/micromamba/envs/npme/lib/python3.10/site-packages (25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /content/micromamba/envs/npme/lib/python3.10/site-packages ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /content/micromamba/envs/npme/lib/python3.10/site-packa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ges (80.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in /content/micromamba/envs/npme/lib/python3.10/site-packag"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es (25.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba run -n npme python -m pip install --no-cache-dir torch==1.13.1+cu116 torchvision==0.14."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1+cu116 -f https://download.pytorch.org/whl/torch_stable.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.13.1 in /content/micromamba/envs/npme/lib/python3.10/site-pa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckages (1.13.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision==0.14.1 in /content/micromamba/envs/npme/lib/python3.10/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ite-packages (0.14.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in /content/micromamba/envs/npme/lib/python3.10/sit"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e-packages (from torch==1.13.1) (4.15.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /content/micromamba/envs/npme/li"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /content/micromamba/envs/npme/lib/pyth"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on3.10/site-packages (from torch==1.13.1) (8.5.0.96)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /content/micromamba/envs/npme/lib/p"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ython3.10/site-packages (from torch==1.13.1) (11.10.3.66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /content/micromamba/envs/npme/lib/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3.10/site-packages (from torch==1.13.1) (11.7.99)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /content/micromamba/envs/npme/lib/python3.10/site-packages ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torchvision==0.14.1) (2.2.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /content/micromamba/envs/npme/lib/python3.10/site-package"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s (from torchvision==0.14.1) (2.32.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /content/micromamba/envs/npme/lib/python3.10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/site-packages (from torchvision==0.14.1) (11.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /content/micromamba/envs/npme/lib/python3.10/site-packa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ges (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (80.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /content/micromamba/envs/npme/lib/python3.10/site-packages ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.45.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset_normalizer<4,>=2 in /content/micromamba/envs/npme/lib/python3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".10/site-packages (from requests->torchvision==0.14.1) (3.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /content/micromamba/envs/npme/lib/python3.10/site-pac"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kages (from requests->torchvision==0.14.1) (3.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /content/micromamba/envs/npme/lib/python3.10/si"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te-packages (from requests->torchvision==0.14.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=201"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4.17 in /content/micromamba/envs/npme/lib/python3.10/site-packages (from requests->torchvision==0."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba run -n npme python -m pip install --no-cache-dir --extra-index-url https://data.pyg.org"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/whl/torch-1.13.1+cu116.html torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geomet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ric==2.3.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-scatter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-sparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-spline-conv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric==2.3.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting requirements to build wheel: finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (pyproject.toml): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /content/micromamba/envs/npme/lib/python3.10/site-packages ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from torch-geometric==2.3.1) (2.2.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 k"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jinja2 (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /content/micromamba/envs/npme/lib/python3.10/site-package"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s (from torch-geometric==2.3.1) (2.32.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyparsing (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (11 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psutil>=5.8.0 (from torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_6"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.manylinux2014_x86_64.whl.metadata (22 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting MarkupSafe>=2.0 (from jinja2->torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata ("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset_normalizer<4,>=2 in /content/micromamba/envs/npme/lib/python3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".10/site-packages (from requests->torch-geometric==2.3.1) (3.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /content/micromamba/envs/npme/lib/python3.10/site-pac"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kages (from requests->torch-geometric==2.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".1 in /content/micromamba/envs/npme/lib/python3.10/site-packages (from requests->torch-geometric==2."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1) (2.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /content/micromamba/envs/npme/lib/python3.10/si"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te-packages (from requests->torch-geometric==2.3.1) (2025.8.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib>=1.2.0 (from scikit-learn->torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->torch-geometric==2.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manylinux2014_x86_64.whl (277 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/9.7 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m8.4/9.7 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/37.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/37.7 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/37.7 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/37.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m26.7/37.7 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m32.0/37.7 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
      "\u001b[?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: torch-geometric, torch-scatter, torch-sparse, torch-cluster,"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch-spline-conv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-geometric (pyproject.toml): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-geometric (pyproject.toml): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910496 sha"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256=15c30a6f63849f2ed8c5d2ec3cb7e22cbfe891b80adc6795eb197440c1704e26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mnz6l3hk/wheels/ac/dc/30/e2874821ff308ee67dcd7a66d"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bde912411e19e35a1addda028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: Building 'torch-scatter' using the legacy setup.py bdist_wheel mechanism, which "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replace"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ment is to use the standardized build interface by setting the `--use-pep517` option, (possibly comb"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-sc"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "atter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-scatter (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-scatter (setup.py): still running...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-scatter (setup.py): still running...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-scatter (setup.py): still running...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-scatter (setup.py): still running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Terminated\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'    set -euxo pipefail\\n\\n    export MAMBA_ROOT_PREFIX=/content/micromamba\\n    if [ ! -d \"$MAMBA_ROOT_PREFIX\" ]; then\\n      curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\\n      install -Dm755 bin/micromamba /usr/local/bin/micromamba\\n    fi\\n\\n    # Cr\\xc3\\xa9er l\\'env si n\\xc3\\xa9cessaire\\n    if ! micromamba env list | grep -q \"^npme\"; then\\n      micromamba create -y -n npme -c conda-forge python=3.10 pip\\n    fi\\n\\n    # Installer la stack dans l\\'env\\n    micromamba run -n npme python -m pip install --upgrade pip wheel setuptools packaging\\n\\n    # Torch 1.13.1 + cu116\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      torch==1.13.1+cu116 torchvision==0.14.1+cu116 \\\\\\n      -f https://download.pytorch.org/whl/torch_stable.html\\n\\n    # PyG wheels pour torch-1.13.1+cu116\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      --extra-index-url https://data.pyg.org/whl/torch-1.13.1+cu116.html \\\\\\n      torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric==2.3.1\\n\\n    # MinkowskiEngine roues (\\xc3\\xa9vite toute compilation CUDA)\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      MinkowskiEngine==0.5.4 -f https://nvidia.github.io/MinkowskiEngine/\\n\\n    # D\\xc3\\xa9pendances repo\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      hydra-core==1.1.0 omegaconf==2.1.0 plyfile==0.8.1 \\\\\\n      scipy==1.10.1 hdbscan==0.8.29 pandas==1.5.3 numba==0.57.1 joblib==1.3.2 tqdm pyyaml\\n\\n    # Sanity check\\n    micromamba run -n npme python - <<\\'PY\\'\\nimport torch, sys\\nprint(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"CUDA available:\", torch.cuda.is_available())\\ntry:\\n    import MinkowskiEngine as ME\\n    print(\"MinkowskiEngine:\", ME.__version__)\\nexcept Exception as e:\\n    print(\"ME import failed:\", e); sys.exit(1)\\ntry:\\n    import torch_geometric\\n    print(\"torch_geometric:\", torch_geometric.__version__)\\nexcept Exception as e:\\n    print(\"pyg import failed:\", e); sys.exit(1)\\nPY\\n'' returned non-zero exit status 143.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m    set -euxo pipefail\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    export MAMBA_ROOT_PREFIX=/content/micromamba\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if [ ! -d \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$MAMBA_ROOT_PREFIX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m ]; then\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      install -Dm755 bin/micromamba /usr/local/bin/micromamba\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    fi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Créer l\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43menv si nécessaire\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    if ! micromamba env list | grep -q \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m^npme\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m; then\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      micromamba create -y -n npme -c conda-forge python=3.10 pip\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    fi\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Installer la stack dans l\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43menv\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install --upgrade pip wheel setuptools packaging\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Torch 1.13.1 + cu116\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install --no-cache-dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      torch==1.13.1+cu116 torchvision==0.14.1+cu116 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      -f https://download.pytorch.org/whl/torch_stable.html\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # PyG wheels pour torch-1.13.1+cu116\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install --no-cache-dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      --extra-index-url https://data.pyg.org/whl/torch-1.13.1+cu116.html \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric==2.3.1\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # MinkowskiEngine roues (évite toute compilation CUDA)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install --no-cache-dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      MinkowskiEngine==0.5.4 -f https://nvidia.github.io/MinkowskiEngine/\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Dépendances repo\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install --no-cache-dir \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      hydra-core==1.1.0 omegaconf==2.1.0 plyfile==0.8.1 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m      scipy==1.10.1 hdbscan==0.8.29 pandas==1.5.3 numba==0.57.1 joblib==1.3.2 tqdm pyyaml\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # Sanity check\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python - <<\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport torch, sys\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorch:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, torch.__version__, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, torch.version.cuda, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCUDA available:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, torch.cuda.is_available())\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtry:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    import MinkowskiEngine as ME\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMinkowskiEngine:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, ME.__version__)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mexcept Exception as e:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mME import failed:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, e); sys.exit(1)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtry:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    import torch_geometric\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorch_geometric:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, torch_geometric.__version__)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mexcept Exception as e:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    print(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyg import failed:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, e); sys.exit(1)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/magics/script.py:348\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    347\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b'    set -euxo pipefail\\n\\n    export MAMBA_ROOT_PREFIX=/content/micromamba\\n    if [ ! -d \"$MAMBA_ROOT_PREFIX\" ]; then\\n      curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\\n      install -Dm755 bin/micromamba /usr/local/bin/micromamba\\n    fi\\n\\n    # Cr\\xc3\\xa9er l\\'env si n\\xc3\\xa9cessaire\\n    if ! micromamba env list | grep -q \"^npme\"; then\\n      micromamba create -y -n npme -c conda-forge python=3.10 pip\\n    fi\\n\\n    # Installer la stack dans l\\'env\\n    micromamba run -n npme python -m pip install --upgrade pip wheel setuptools packaging\\n\\n    # Torch 1.13.1 + cu116\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      torch==1.13.1+cu116 torchvision==0.14.1+cu116 \\\\\\n      -f https://download.pytorch.org/whl/torch_stable.html\\n\\n    # PyG wheels pour torch-1.13.1+cu116\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      --extra-index-url https://data.pyg.org/whl/torch-1.13.1+cu116.html \\\\\\n      torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric==2.3.1\\n\\n    # MinkowskiEngine roues (\\xc3\\xa9vite toute compilation CUDA)\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      MinkowskiEngine==0.5.4 -f https://nvidia.github.io/MinkowskiEngine/\\n\\n    # D\\xc3\\xa9pendances repo\\n    micromamba run -n npme python -m pip install --no-cache-dir \\\\\\n      hydra-core==1.1.0 omegaconf==2.1.0 plyfile==0.8.1 \\\\\\n      scipy==1.10.1 hdbscan==0.8.29 pandas==1.5.3 numba==0.57.1 joblib==1.3.2 tqdm pyyaml\\n\\n    # Sanity check\\n    micromamba run -n npme python - <<\\'PY\\'\\nimport torch, sys\\nprint(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"CUDA available:\", torch.cuda.is_available())\\ntry:\\n    import MinkowskiEngine as ME\\n    print(\"MinkowskiEngine:\", ME.__version__)\\nexcept Exception as e:\\n    print(\"ME import failed:\", e); sys.exit(1)\\ntry:\\n    import torch_geometric\\n    print(\"torch_geometric:\", torch_geometric.__version__)\\nexcept Exception as e:\\n    print(\"pyg import failed:\", e); sys.exit(1)\\nPY\\n'' returned non-zero exit status 143."
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "    set -euxo pipefail\n",
    "\n",
    "    export MAMBA_ROOT_PREFIX=/content/micromamba\n",
    "    if [ ! -d \"$MAMBA_ROOT_PREFIX\" ]; then\n",
    "      curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
    "      install -Dm755 bin/micromamba /usr/local/bin/micromamba\n",
    "    fi\n",
    "\n",
    "    # Créer l'env si nécessaire\n",
    "    if ! micromamba env list | grep -q \"^npme\"; then\n",
    "      micromamba create -y -n npme -c conda-forge python=3.10 pip\n",
    "    fi\n",
    "\n",
    "    # Installer la stack dans l'env\n",
    "    micromamba run -n npme python -m pip install --upgrade pip wheel setuptools packaging\n",
    "\n",
    "    # Torch 1.13.1 + cu116\n",
    "    micromamba run -n npme python -m pip install --no-cache-dir \\\n",
    "      torch==1.13.1+cu116 torchvision==0.14.1+cu116 \\\n",
    "      -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "    # PyG wheels pour torch-1.13.1+cu116\n",
    "    micromamba run -n npme python -m pip install --no-cache-dir \\\n",
    "      --extra-index-url https://data.pyg.org/whl/torch-1.13.1+cu116.html \\\n",
    "      torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric==2.3.1\n",
    "\n",
    "    # MinkowskiEngine roues (évite toute compilation CUDA)\n",
    "    micromamba run -n npme python -m pip install --no-cache-dir \\\n",
    "      MinkowskiEngine==0.5.4 -f https://nvidia.github.io/MinkowskiEngine/\n",
    "\n",
    "    # Dépendances repo\n",
    "    micromamba run -n npme python -m pip install --no-cache-dir \\\n",
    "      hydra-core==1.1.0 omegaconf==2.1.0 plyfile==0.8.1 \\\n",
    "      scipy==1.10.1 hdbscan==0.8.29 pandas==1.5.3 numba==0.57.1 joblib==1.3.2 tqdm pyyaml\n",
    "\n",
    "    # Sanity check\n",
    "    micromamba run -n npme python - <<'PY'\n",
    "import torch, sys\n",
    "print(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"CUDA available:\", torch.cuda.is_available())\n",
    "try:\n",
    "    import MinkowskiEngine as ME\n",
    "    print(\"MinkowskiEngine:\", ME.__version__)\n",
    "except Exception as e:\n",
    "    print(\"ME import failed:\", e); sys.exit(1)\n",
    "try:\n",
    "    import torch_geometric\n",
    "    print(\"torch_geometric:\", torch_geometric.__version__)\n",
    "except Exception as e:\n",
    "    print(\"pyg import failed:\", e); sys.exit(1)\n",
    "PY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee098613",
   "metadata": {},
   "source": [
    "## 2) Cloner ton fork du repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cffdc06f",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:19.871295Z",
     "iopub.status.busy": "2025-09-17T07:32:19.870766Z",
     "iopub.status.idle": "2025-09-17T07:32:19.927549Z",
     "shell.execute_reply": "2025-09-17T07:32:19.926079Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ REPO_URL=https://github.com/Ludwig-H/PanopticSegForLargeScalePointCloud\n",
      "+ '[' '!' -d PanopticSegFo"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rLargeScalePointCloud ']'\n",
      "+ cd PanopticSegForLargeScalePointCloud\n",
      "+ mkdir -p data/npm3dfused/raw out"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "puts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ echo 'Repo ok.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo ok.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "\n",
    "REPO_URL=\"https://github.com/Ludwig-H/PanopticSegForLargeScalePointCloud\"\n",
    "if [ ! -d PanopticSegForLargeScalePointCloud ]; then\n",
    "  git clone --depth=1 \"$REPO_URL\"\n",
    "fi\n",
    "cd PanopticSegForLargeScalePointCloud\n",
    "mkdir -p data/npm3dfused/raw outputs\n",
    "echo \"Repo ok.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04e289",
   "metadata": {},
   "source": [
    "## 3) Télécharger NPM3D (labels d’instances) dans `data/npm3dfused/raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36edfb60",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:19.931941Z",
     "iopub.status.busy": "2025-09-17T07:32:19.931413Z",
     "iopub.status.idle": "2025-09-17T07:32:19.997907Z",
     "shell.execute_reply": "2025-09-17T07:32:19.996572Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud/data/npm3dfused/raw\n",
      "+ base=https://zenodo.org/records/811898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6/files\n",
      "+ files=(\"Paris_train.ply\" \"Paris_val.ply\" \"Paris_test.ply\" \"Lille1_1_train.ply\" \"Lille1_1_v"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "al.ply\" \"Lille1_1_test.ply\" \"Lille1_2_train.ply\" \"Lille1_2_val.ply\" \"Lille1_2_test.ply\" \"Lille2_trai"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n.ply\" \"Lille2_val.ply\" \"Lille2_test.ply\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ for f in \"${files[@]}\"\n",
      "+ '[' '!' -f Paris_train.ply ']'\n",
      "+ echo 'Already have Paris_train.ply'\n",
      "+ fo"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r f in \"${files[@]}\"\n",
      "+ '[' '!' -f Paris_val.ply ']'\n",
      "+ echo 'Already have Paris_val.ply'\n",
      "+ for f in \""
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "${files[@]}\"\n",
      "+ '[' '!' -f Paris_test.ply ']'\n",
      "+ echo 'Already have Paris_test.ply'\n",
      "+ for f in \"${file"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s[@]}\"\n",
      "+ '[' '!' -f Lille1_1_train.ply ']'\n",
      "+ echo 'Already have Lille1_1_train.ply'\n",
      "+ for f in \"${fi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "les[@]}\"\n",
      "+ '[' '!' -f Lille1_1_val.ply ']'\n",
      "+ echo 'Already have Lille1_1_val.ply'\n",
      "+ for f in \"${file"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s[@]}\"\n",
      "+ '[' '!' -f Lille1_1_test.ply ']'\n",
      "+ echo 'Already have Lille1_1_test.ply'\n",
      "+ for f in \"${file"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s[@]}\"\n",
      "+ '[' '!' -f Lille1_2_train.ply ']'\n",
      "+ echo 'Already have Lille1_2_train.ply'\n",
      "+ for f in \"${fi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "les[@]}\"\n",
      "+ '[' '!' -f Lille1_2_val.ply ']'\n",
      "+ echo 'Already have Lille1_2_val.ply'\n",
      "+ for f in \"${file"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s[@]}\"\n",
      "+ '[' '!' -f Lille1_2_test.ply ']'\n",
      "+ echo 'Already have Lille1_2_test.ply'\n",
      "+ for f in \"${file"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s[@]}\"\n",
      "+ '[' '!' -f Lille2_train.ply ']'\n",
      "+ echo 'Already have Lille2_train.ply'\n",
      "+ for f in \"${files["
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "@]}\"\n",
      "+ '[' '!' -f Lille2_val.ply ']'\n",
      "+ echo 'Already have Lille2_val.ply'\n",
      "+ for f in \"${files[@]}\"\n",
      "+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " '[' '!' -f Lille2_test.ply ']'\n",
      "+ echo 'Already have Lille2_test.ply'\n",
      "+ ls -lh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have Paris_train.ply\n",
      "Already have Paris_val.ply\n",
      "Already have Paris_test.ply\n",
      "Already have Lil"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le1_1_train.ply\n",
      "Already have Lille1_1_val.ply\n",
      "Already have Lille1_1_test.ply\n",
      "Already have Lille1_2_t"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rain.ply\n",
      "Already have Lille1_2_val.ply\n",
      "Already have Lille1_2_test.ply\n",
      "Already have Lille2_train.ply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have Lille2_val.ply\n",
      "Already have Lille2_test.ply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 48K\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Lille1_1_test.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 07:12 Lille1_1_train.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Lille1_1_val.ply\n",
      "-rw-r--r-- 1 roo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t root 125 Sep 17 07:12 Lille1_2_test.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Lille1_2_train.ply"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Lille1_2_val.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Li"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lle2_test.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Lille2_train.ply\n",
      "-rw-r--r-- 1 root root 125 Se"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p 17 07:12 Lille2_val.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Paris_test.ply\n",
      "-rw-r--r-- 1 root r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oot 125 Sep 17 07:12 Paris_train.ply\n",
      "-rw-r--r-- 1 root root 125 Sep 17 07:12 Paris_val.ply\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd PanopticSegForLargeScalePointCloud/data/npm3dfused/raw\n",
    "\n",
    "base=\"https://zenodo.org/records/8118986/files\"\n",
    "files=(\n",
    "  \"Paris_train.ply\" \"Paris_val.ply\" \"Paris_test.ply\"\n",
    "  \"Lille1_1_train.ply\" \"Lille1_1_val.ply\" \"Lille1_1_test.ply\"\n",
    "  \"Lille1_2_train.ply\" \"Lille1_2_val.ply\" \"Lille1_2_test.ply\"\n",
    "  \"Lille2_train.ply\" \"Lille2_val.ply\" \"Lille2_test.ply\"\n",
    ")\n",
    "for f in \"${files[@]}\"; do\n",
    "  if [ ! -f \"$f\" ]; then\n",
    "    echo \"Downloading $f\"\n",
    "    wget -q --show-progress \"${base}/${f}?download=1\" -O \"$f\"\n",
    "  else\n",
    "    echo \"Already have $f\"\n",
    "  fi\n",
    "done\n",
    "ls -lh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8b71d",
   "metadata": {},
   "source": [
    "## 4) (Optionnel) Entraînement Setting IV (rayon 16 m, voxel 0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc71a1c",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:20.000937Z",
     "iopub.status.busy": "2025-09-17T07:32:20.000487Z",
     "iopub.status.idle": "2025-09-17T07:32:20.031736Z",
     "shell.execute_reply": "2025-09-17T07:32:20.030629Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n",
      "+ export WANDB_MODE=offline\n",
      "+ WANDB_MODE=offline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ echo 'Exemple de commande (désactivée par défaut) :'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de commande (désactivée par défaut) :\n",
      "micromamba run -n npme python train.py task=panopti"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c \\\n",
      "  data=panoptic/npm3d-sparseconv_grid_012_R_16_cylinder_area1 \\\n",
      "  models=panoptic/area4_ablation"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_3heads_5 model_name=PointGroup-PAPER \\\n",
      "  training=7_area1 job_name=A1_S7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ echo 'micromamba run -n npme python train.py task=panoptic \\\n",
      "  data=panoptic/npm3d-sparseconv_grid"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_012_R_16_cylinder_area1 \\\n",
      "  models=panoptic/area4_ablation_3heads_5 model_name=PointGroup-PAPER \\\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " training=7_area1 job_name=A1_S7'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd PanopticSegForLargeScalePointCloud\n",
    "export WANDB_MODE=offline\n",
    "\n",
    "echo \"Exemple de commande (désactivée par défaut) :\"\n",
    "echo \"micromamba run -n npme python train.py task=panoptic \\\\\n",
    "  data=panoptic/npm3d-sparseconv_grid_012_R_16_cylinder_area1 \\\\\n",
    "  models=panoptic/area4_ablation_3heads_5 model_name=PointGroup-PAPER \\\\\n",
    "  training=7_area1 job_name=A1_S7\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317996d",
   "metadata": {},
   "source": [
    "## 5) Adapter `conf/eval.yaml` et préparer un checkpoint\n",
    "Si tu n’entraînes pas dans cette session, monte ton Drive et pointe `CKPT_PATH` sur un checkpoint `best.pth` existant.\n",
    "Le fichier `conf/eval.yaml` contrôle chemins et split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161ccc43",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:20.035455Z",
     "iopub.status.busy": "2025-09-17T07:32:20.035113Z",
     "iopub.status.idle": "2025-09-17T07:32:20.131086Z",
     "shell.execute_reply": "2025-09-17T07:32:20.129953Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ echo 'Aperçu conf/eval.yaml (éditable si besoin):'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu conf/eval.yaml (éditable si besoin):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ sed -n 1,200p conf/eval.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaults: \n",
      "  - visualization: eval\n",
      "\n",
      "num_workers: 0\n",
      "batch_size: 1\n",
      "cuda: 0\n",
      "weight_name: \"latest\" # Use"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d during resume, select with model to load from [miou, macc, acc..., latest]\n",
      "enable_cudnn: True\n",
      "#TO "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAPT\n",
      "#checkpoint_dir specifies path to the directory where the trained model (that should be used f"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or evaluation) and the used configurations are saved,\n",
      "#e.g. /path/to/project/PanopticSegForLargeScal"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ePointCloud/outputs/treeins_my_first_run/treeins_my_first_run-PointGroup-PAPER-20230705_215106\"\n",
      "chec"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpoint_dir: \"/path/to/project/PanopticSegForLargeScalePointCloud/outputs/treeins_my_first_run/treein"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_my_first_run-PointGroup-PAPER-20230705_215106\"\n",
      "model_name: PointGroup-PAPER\n",
      "precompute_multi_scale"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": True # Compute multiscate features on cpu for faster training / inference\n",
      "enable_dropout: False\n",
      "vo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ting_runs: 1\n",
      "data: \n",
      "  #TO ADAPT\n",
      "  #fold: list of .ply test file paths, e.g. ['/path/to/project/Panop"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticSegForLargeScalePointCloud/data/treeinsfused/raw/SCION/SCION_plot_31_annotated_test.ply', '/path/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/SCION/SCION_plot_61_annotated_te"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st.ply']\n",
      "  #fold: [\"/path/to/project/PanopticSegForLargeScalePointCloud/data/npm3dfused/raw/Paris_te"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st.ply\"]\n",
      "  #fold: [\"/path/to/project/PanopticSegForLargeScalePointCloud/data/npm3dfused/raw/Lille1_1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_test.ply\"]\n",
      "  fold: ['/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/CULS"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/CULS_plot_2_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used/raw/NIBIO/NIBIO_plot_1_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointClou"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d/data/treeinsfused/raw/NIBIO/NIBIO_plot_17_annotated_test.ply', '/path/to/project/PanopticSegForLar"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geScalePointCloud/data/treeinsfused/raw/NIBIO/NIBIO_plot_18_annotated_test.ply', '/path/to/project/P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO/NIBIO_plot_22_annotated_test.ply', '/p"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ath/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO/NIBIO_plot_23_annotate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO/NIBIO_"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_5_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aw/NIBIO2/NIBIO2_plot1_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/dat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a/treeinsfused/raw/NIBIO2/NIBIO2_plot10_annotated_test.ply', '/path/to/project/PanopticSegForLargeSc"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot15_annotated_test.ply', '/path/to/project/Pano"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot27_annotated_test.ply', '/pat"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot3_annotated_"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot32_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aw/NIBIO2/NIBIO2_plot34_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/da"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta/treeinsfused/raw/NIBIO2/NIBIO2_plot35_annotated_test.ply', '/path/to/project/PanopticSegForLargeS"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot48_annotated_test.ply', '/path/to/project/Pan"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot49_annotated_test.ply', '/pa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot52_annotate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_plot53_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raw/NIBIO2/NIBIO2_plot58_annotated_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/treeinsfused/raw/NIBIO2/NIBIO2_plot6_annotated_test.ply', '/path/to/project/PanopticSegForLarge"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalePointCloud/data/treeinsfused/raw/NIBIO2/NIBIO2_plot60_annotated_test.ply', '/path/to/project/Pa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nopticSegForLargeScalePointCloud/data/treeinsfused/raw/RMIT/RMIT_test_test.ply', '/path/to/project/P"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anopticSegForLargeScalePointCloud/data/treeinsfused/raw/SCION/SCION_plot_31_annotated_test.ply', '/p"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ath/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/SCION/SCION_plot_61_annotate"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_test.ply', '/path/to/project/PanopticSegForLargeScalePointCloud/data/treeinsfused/raw/TUWIEN/TUWIE"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_test_test.ply']\n",
      "  \n",
      "\n",
      "tracker_options: # Extra options for the tracker\n",
      "  full_res: True\n",
      "  make_submi"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssion: True\n",
      "  ply_output: \"vote1regular.ply\"\n",
      "\n",
      "hydra:\n",
      "  run:\n",
      "    dir: ${checkpoint_dir}/eval/${now:%Y"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-%m-%d_%H-%M-%S}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd PanopticSegForLargeScalePointCloud\n",
    "echo \"Aperçu conf/eval.yaml (éditable si besoin):\"\n",
    "sed -n '1,200p' conf/eval.yaml || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf6fc3",
   "metadata": {},
   "source": [
    "## 6) Extraction **embeddings 5D** avant clustering\n",
    "On ajoute un script indépendant qui charge le modèle/dataloader d’éval via Hydra, accroche un hook sur la tête d’embedding et dump des `.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6900a08a",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:20.135668Z",
     "iopub.status.busy": "2025-09-17T07:32:20.135168Z",
     "iopub.status.idle": "2025-09-17T07:32:20.185457Z",
     "shell.execute_reply": "2025-09-17T07:32:20.184195Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ echo 'tools_extract_embeddings.py créé.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tools_extract_embeddings.py créé.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "    set -euxo pipefail\n",
    "    cd PanopticSegForLargeScalePointCloud\n",
    "\n",
    "    cat > tools_extract_embeddings.py << 'PY'\n",
    "import os, re, numpy as np, torch\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Stratégie: réutiliser la construction des loaders & du modèle d'eval.\n",
    "# Le repo expose généralement des helpers dans eval.py; sinon, on importe train/eval et\n",
    "# cherche les objets dans le namespace hydra.\n",
    "\n",
    "def _attach_first_embed_hook(model, bucket):\n",
    "    chosen = None\n",
    "    for name, m in model.named_modules():\n",
    "        if re.search(r\"(emb|embed|embedding)\", name, re.I):\n",
    "            chosen = (name, m)\n",
    "            break\n",
    "    if chosen is None:\n",
    "        print(\"[extract] Aucun module 'emb*' trouvé; on essaiera de lire la sortie du forward dict.\")\n",
    "        return None\n",
    "    name, mod = chosen\n",
    "    print(f\"[extract] Hook sur '{name}'\")\n",
    "    def _hook(module, inp, out):\n",
    "        try:\n",
    "            E = out.detach().float().cpu().numpy()\n",
    "            bucket.append(E)\n",
    "        except Exception as e:\n",
    "            print(\"[extract] hook fail:\", e)\n",
    "    h = mod.register_forward_hook(lambda m,i,o: _hook(m,i,o))\n",
    "    return h\n",
    "\n",
    "@hydra.main(config_path=\"conf\", config_name=\"eval\", version_base=None)\n",
    "def main(cfg: DictConfig):\n",
    "    # On s'appuie sur les mêmes builders que eval.py\n",
    "    # Les fonctions peuvent s'appeler différemment selon commit; on essaye plusieurs options.\n",
    "    build_ok = False\n",
    "    model = None; loaders = None; device = None; test_split = None\n",
    "    try:\n",
    "        from eval import build_model_and_loaders\n",
    "        model, loaders, device, test_split = build_model_and_loaders(cfg)\n",
    "        build_ok = True\n",
    "        print(\"[extract] build_model_and_loaders OK\")\n",
    "    except Exception as e:\n",
    "        print(\"[extract] Pas de build_model_and_loaders dans eval.py:\", e)\n",
    "\n",
    "    if not build_ok:\n",
    "        try:\n",
    "            # Certains repos exposent make_model, make_dataloaders\n",
    "            from eval import make_model, make_dataloaders, get_device\n",
    "            device = get_device(cfg)\n",
    "            model = make_model(cfg).to(device).eval()\n",
    "            loaders, test_split = make_dataloaders(cfg)\n",
    "            build_ok = True\n",
    "            print(\"[extract] make_model/make_dataloaders OK\")\n",
    "        except Exception as e:\n",
    "            print(\"[extract] Echec construction modèle/loaders:\", e)\n",
    "            raise SystemExit(1)\n",
    "\n",
    "    out_root = Path(\"outputs/embeddings\")\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    bucket = []\n",
    "    hook = _attach_first_embed_hook(model, bucket)\n",
    "\n",
    "    test_loader = loaders.get(test_split, None) or loaders.get(\"test\", None)\n",
    "    if test_loader is None:\n",
    "        print(\"[extract] test_loader introuvable. Clés:\", list(loaders.keys()))\n",
    "        raise SystemExit(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ib, batch in enumerate(test_loader):\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            # Si le modèle retourne un dict avec une clé embeddings*\n",
    "            if isinstance(out, dict):\n",
    "                for k in [\"embedding\", \"embeddings\", \"embedding_5d\", \"emb_5d\", \"panoptic_embeddings\"]:\n",
    "                    if k in out and isinstance(out[k], torch.Tensor):\n",
    "                        E = out[k].detach().cpu().float().numpy()\n",
    "                        bucket.append(E)\n",
    "                        break\n",
    "            if not bucket:\n",
    "                print(f\"[extract] WARNING: pas d'embeddings capturés pour batch {ib}.\")\n",
    "                continue\n",
    "            E = bucket[-1]\n",
    "            idx = getattr(batch, \"idx\", None)\n",
    "            if idx is None and hasattr(batch, \"ptr\"):\n",
    "                idx = batch.ptr\n",
    "            if idx is None:\n",
    "                idx = torch.arange(E.shape[0], device=E.device)\n",
    "            idx = idx.detach().cpu().numpy()\n",
    "            tag = f\"batch_{ib:05d}\"\n",
    "            np.savez_compressed(out_root / f\"{tag}.npz\", embeddings=E, indices=idx)\n",
    "            print(f\"[extract] saved {tag}: {E.shape}\")\n",
    "    if hook is not None:\n",
    "        hook.remove()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "PY\n",
    "\n",
    "    echo \"tools_extract_embeddings.py créé.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc53fdc",
   "metadata": {},
   "source": [
    "## 7) Lancer éval officielle puis extraction d’embeddings\n",
    "Adapte `CKPT_PATH` si besoin. Tu peux aussi surcharger la conf Hydra en CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e1b2d7",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:20.189022Z",
     "iopub.status.busy": "2025-09-17T07:32:20.188546Z",
     "iopub.status.idle": "2025-09-17T07:32:23.119424Z",
     "shell.execute_reply": "2025-09-17T07:32:23.118692Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ export CKPT_PATH=/content/drive/MyDrive/panoptic_runs/A1_S7/checkpoints/best.pth\n",
      "+ CKPT_PATH=/cont"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ent/drive/MyDrive/panoptic_runs/A1_S7/checkpoints/best.pth\n",
      "+ echo 'Si nécessaire, lance l'\\''éval "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(désactivée ici si conf déjà prête):'\n",
      "+ echo 'micromamba run -n npme python eval.py'\n",
      "+ echo 'Ex"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "traction embeddings:'\n",
      "+ micromamba run -n npme python tools_extract_embeddings.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si nécessaire, lance l'éval (désactivée ici si conf déjà prête):\n",
      "micromamba run -n npme pytho"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n eval.py\n",
      "Extraction embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/workspace/PanopticSegForLargeScalePointCloud/tools_extract_embeddings.py\", line 3, in <modu"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "le>\n",
      "    import hydra\n",
      "ModuleNotFoundError: No module named 'hydra'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ ls -lh outputs/embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'outputs/embeddings': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd PanopticSegForLargeScalePointCloud\n",
    "\n",
    "# Exemple: pointer vers un checkpoint existant (modifie ce chemin selon ton stockage)\n",
    "export CKPT_PATH=\"${CKPT_PATH:-/content/drive/MyDrive/panoptic_runs/A1_S7/checkpoints/best.pth}\"\n",
    "\n",
    "echo \"Si nécessaire, lance l'éval (désactivée ici si conf déjà prête):\"\n",
    "echo \"micromamba run -n npme python eval.py\"\n",
    "\n",
    "echo \"Extraction embeddings:\"\n",
    "micromamba run -n npme python tools_extract_embeddings.py || true\n",
    "ls -lh outputs/embeddings || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0809613",
   "metadata": {},
   "source": [
    "## 8) Brancher ton clusterer sur les embeddings `.npz`\n",
    "Cette cellule de **démonstration** lit tous les `.npz`, normalise, applique un clusterer bidon et sauve un `instance_labels.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492b81cc",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:23.123591Z",
     "iopub.status.busy": "2025-09-17T07:32:23.123276Z",
     "iopub.status.idle": "2025-09-17T07:32:39.537323Z",
     "shell.execute_reply": "2025-09-17T07:32:39.534720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba run -n npme python -m pip install scikit-learn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (11 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.22.0 in /content/micromamba/envs/npme/lib/python3.10/site-pa"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckages (from scikit-learn) (2.2.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy>=1.8.0 (from scikit-learn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 k"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib>=1.2.0 (from scikit-learn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
      "\u001b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m9.4/9.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/37.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/37.7 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/37.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m34.6/37.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m37.5/37.7 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [scipy]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [joblib]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [scikit-learn]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn]\n",
      "\u001b[?25h\r",
      "\u001b[1A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ micromamba run -n npme python tools_cluster_with_embeddings.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aucun embedding trouvé. Vérifie l'étape précédente.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'    set -euxo pipefail\\n    cd PanopticSegForLargeScalePointCloud\\n\\n    cat > tools_cluster_with_embeddings.py << \\'PY\\'\\nimport os, glob, numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\n\\nemb_dir = \"outputs/embeddings\"\\nout_path = \"outputs/instance_labels.npy\"\\n\\ndef load_all_npz(d):\\n    Xs, Is = [], []\\n    for f in sorted(glob.glob(os.path.join(d, \"*.npz\"))):\\n        d = np.load(f)\\n        Xs.append(d[\"embeddings\"])\\n        Is.append(d[\"indices\"])\\n    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0,5), dtype=np.float32)\\n    I = np.concatenate(Is, axis=0) if Is else np.zeros((0,), dtype=np.int64)\\n    return X, I\\n\\ndef my_clusterer(X):\\n    # TODO: remplace par ton algo\\n    return np.zeros(X.shape[0], dtype=np.int32)\\n\\nX, I = load_all_npz(emb_dir)\\nif X.shape[0] == 0:\\n    raise SystemExit(\"Aucun embedding trouv\\xc3\\xa9. V\\xc3\\xa9rifie l\\'\\xc3\\xa9tape pr\\xc3\\xa9c\\xc3\\xa9dente.\")\\nXn = StandardScaler().fit_transform(X)\\nlabels = my_clusterer(Xn)\\nnp.save(out_path, labels)\\nprint(\"Saved:\", out_path, labels.shape)\\nPY\\n\\n    micromamba run -n npme python -m pip install scikit-learn || true\\n    micromamba run -n npme python tools_cluster_with_embeddings.py\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m    set -euxo pipefail\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cd PanopticSegForLargeScalePointCloud\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    cat > tools_cluster_with_embeddings.py << \u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mimport os, glob, numpy as np\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mfrom sklearn.preprocessing import StandardScaler\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43memb_dir = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mout_path = \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs/instance_labels.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdef load_all_npz(d):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    Xs, Is = [], []\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    for f in sorted(glob.glob(os.path.join(d, \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*.npz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m))):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        d = np.load(f)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        Xs.append(d[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m        Is.append(d[\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m])\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0,5), dtype=np.float32)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    I = np.concatenate(Is, axis=0) if Is else np.zeros((0,), dtype=np.int64)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return X, I\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mdef my_clusterer(X):\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    # TODO: remplace par ton algo\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    return np.zeros(X.shape[0], dtype=np.int32)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mX, I = load_all_npz(emb_dir)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mif X.shape[0] == 0:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    raise SystemExit(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAucun embedding trouvé. Vérifie l\u001b[39;49m\u001b[38;5;130;43;01m\\'\u001b[39;49;00m\u001b[33;43métape précédente.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mXn = StandardScaler().fit_transform(X)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mlabels = my_clusterer(Xn)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mnp.save(out_path, labels)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mprint(\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSaved:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m, out_path, labels.shape)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mPY\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python -m pip install scikit-learn || true\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    micromamba run -n npme python tools_cluster_with_embeddings.py\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/site-packages/IPython/core/magics/script.py:348\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    347\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b'    set -euxo pipefail\\n    cd PanopticSegForLargeScalePointCloud\\n\\n    cat > tools_cluster_with_embeddings.py << \\'PY\\'\\nimport os, glob, numpy as np\\nfrom sklearn.preprocessing import StandardScaler\\n\\nemb_dir = \"outputs/embeddings\"\\nout_path = \"outputs/instance_labels.npy\"\\n\\ndef load_all_npz(d):\\n    Xs, Is = [], []\\n    for f in sorted(glob.glob(os.path.join(d, \"*.npz\"))):\\n        d = np.load(f)\\n        Xs.append(d[\"embeddings\"])\\n        Is.append(d[\"indices\"])\\n    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0,5), dtype=np.float32)\\n    I = np.concatenate(Is, axis=0) if Is else np.zeros((0,), dtype=np.int64)\\n    return X, I\\n\\ndef my_clusterer(X):\\n    # TODO: remplace par ton algo\\n    return np.zeros(X.shape[0], dtype=np.int32)\\n\\nX, I = load_all_npz(emb_dir)\\nif X.shape[0] == 0:\\n    raise SystemExit(\"Aucun embedding trouv\\xc3\\xa9. V\\xc3\\xa9rifie l\\'\\xc3\\xa9tape pr\\xc3\\xa9c\\xc3\\xa9dente.\")\\nXn = StandardScaler().fit_transform(X)\\nlabels = my_clusterer(Xn)\\nnp.save(out_path, labels)\\nprint(\"Saved:\", out_path, labels.shape)\\nPY\\n\\n    micromamba run -n npme python -m pip install scikit-learn || true\\n    micromamba run -n npme python tools_cluster_with_embeddings.py\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "    set -euxo pipefail\n",
    "    cd PanopticSegForLargeScalePointCloud\n",
    "\n",
    "    cat > tools_cluster_with_embeddings.py << 'PY'\n",
    "import os, glob, numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "emb_dir = \"outputs/embeddings\"\n",
    "out_path = \"outputs/instance_labels.npy\"\n",
    "\n",
    "def load_all_npz(d):\n",
    "    Xs, Is = [], []\n",
    "    for f in sorted(glob.glob(os.path.join(d, \"*.npz\"))):\n",
    "        d = np.load(f)\n",
    "        Xs.append(d[\"embeddings\"])\n",
    "        Is.append(d[\"indices\"])\n",
    "    X = np.concatenate(Xs, axis=0) if Xs else np.zeros((0,5), dtype=np.float32)\n",
    "    I = np.concatenate(Is, axis=0) if Is else np.zeros((0,), dtype=np.int64)\n",
    "    return X, I\n",
    "\n",
    "def my_clusterer(X):\n",
    "    # TODO: remplace par ton algo\n",
    "    return np.zeros(X.shape[0], dtype=np.int32)\n",
    "\n",
    "X, I = load_all_npz(emb_dir)\n",
    "if X.shape[0] == 0:\n",
    "    raise SystemExit(\"Aucun embedding trouvé. Vérifie l'étape précédente.\")\n",
    "Xn = StandardScaler().fit_transform(X)\n",
    "labels = my_clusterer(Xn)\n",
    "np.save(out_path, labels)\n",
    "print(\"Saved:\", out_path, labels.shape)\n",
    "PY\n",
    "\n",
    "    micromamba run -n npme python -m pip install scikit-learn || true\n",
    "    micromamba run -n npme python tools_cluster_with_embeddings.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35917da",
   "metadata": {},
   "source": [
    "## 9) Évaluation finale (scripts officiels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "072b6d5d",
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2025-09-17T07:32:39.546556Z",
     "iopub.status.busy": "2025-09-17T07:32:39.545783Z",
     "iopub.status.idle": "2025-09-17T07:32:39.741057Z",
     "shell.execute_reply": "2025-09-17T07:32:39.739011Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ cd PanopticSegForLargeScalePointCloud\n",
      "+ micromamba run -n npme python evaluation_stats_NPM3D.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspace/PanopticSegForLargeScalePointCloud/evaluation_"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stats_NPM3D.py\", line 4, in <module>\n",
      "    from plyfile import PlyData, PlyElement\n",
      "ModuleNotFoundError"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": No module named 'plyfile'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%bash\n",
    "set -euxo pipefail\n",
    "cd PanopticSegForLargeScalePointCloud\n",
    "micromamba run -n npme python evaluation_stats_NPM3D.py || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edce32",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Si tu tiens absolument à rester en Python 3.12/Torch 2.x natif, **MinkowskiEngine** risque de ne pas avoir de roue binaire. Ne compile pas en Colab, c’est peine perdue sans toolkit CUDA complet. L’env micromamba **résout le problème proprement**.\n",
    "- Tu peux dupliquer l’éval sur `area{1..4}` (4-fold) en adaptant la conf Hydra comme dans le README.\n",
    "- Si la capture d’embeddings ne prend pas, imprime `model.named_modules()` et ajuste le motif de recherche `'emb'` dans `tools_extract_embeddings.py`."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NPM3D_PanopticSeg_embeddings_eval_micromamba.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
