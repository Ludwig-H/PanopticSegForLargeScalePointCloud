{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "NPM3D_PanopticSeg_embeddings_and_eval.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NPM3D Panoptic Segmentation — embeddings + eval (ETH pipeline)\n\n**Repo**: fork of `prs-eth/PanopticSegForLargeScalePointCloud`.\n\nCe notebook Colab installe l'environnement, récupère NPM3D (avec labels d'instances),\nlance l'entraînement/éval avec les configs des auteurs, **extrait les embeddings 5D** avant le clustering,\net calcule les métriques officielles (F1 / PQ / etc.).\n\n⚙️ GPU requis (Colab Pro conseillé)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Vérifier le GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\nimport os, subprocess, sys, platform, torch\n# torch may not be installed yet; guard\ntry:\n    import torch\n    print(\"Torch version:\", torch.__version__)\n    print(\"CUDA available:\", torch.cuda.is_available())\n    if torch.cuda.is_available():\n        print(\"CUDA device:\", torch.cuda.get_device_name(0))\nexcept Exception as e:\n    print(\"Torch not yet installed:\", e)\n!nvidia-smi || true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Dépendances système (OpenBLAS pour MinkowskiEngine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\nsudo apt-get update -y\nsudo apt-get install -y build-essential git cmake libopenblas-dev libomp-dev\n# Optional but useful for large builds\nsudo apt-get install -y ninja-build\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) PyTorch 1.9.0 (cu111) + PyG wheels (compatibles) + MinkowskiEngine\nLes auteurs indiquent PyTorch 1.9.0 + cu111, torch-scatter/sparse correspondants et MinkowskiEngine compilé **avec OpenBLAS**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n    %%bash\n    set -euxo pipefail\n    # Désinstaller torch/torchvision existants\n    pip uninstall -y torch torchvision torchaudio || true\n\n    # Installer torch 1.9.0 + cu111 et torchvision 0.10.0 + cu111\n    pip install --no-cache-dir torch==1.9.0+cu111 torchvision==0.10.0+cu111 \\\n        -f https://download.pytorch.org/whl/torch_stable.html\n\n    python - << 'PY'\nimport torch, sys\nprint(\"Torch:\", torch.__version__, \"CUDA ok:\", torch.cuda.is_available())\nassert torch.__version__.startswith(\"1.9\"), \"Torch 1.9.x requis\"\nPY\n\n    # PyG wheels compatibles avec torch 1.9.0+cu111\n    pip install --no-cache-dir torch-scatter==2.0.8 -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n    pip install --no-cache-dir torch-sparse==0.6.12 -f https://data.pyg.org/whl/torch-1.9.0+cu111.html\n    pip install --no-cache-dir torch-geometric==1.7.2\n\n    # Dépendances Python supplémentaires\n    pip install --no-cache-dir hydra-core==1.1.0 omegaconf==2.1.0 plyfile==0.8.1 \\\n        scipy==1.7.3 hdbscan==0.8.27 pandas==1.3.5 numba==0.55.1 joblib==1.1.0 tqdm pyyaml\n\n    # MinkowskiEngine depuis source (OpenBLAS)\n    # Rem: Colab a souvent /usr/include pour cblas.h via libopenblas-dev\n    git clone --depth=1 https://github.com/NVIDIA/MinkowskiEngine.git\n    pushd MinkowskiEngine\n    python setup.py install --blas_include_dirs=/usr/include --blas=openblas\n    popd\n\n    python - << 'PY'\ntry:\n    import MinkowskiEngine as ME\n    print(\"MinkowskiEngine:\", ME.__version__)\nexcept Exception as e:\n    raise SystemExit(\"Echec import MinkowskiEngine: %s\" % e)\nPY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Cloner votre fork et préparer l'arborescence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\nREPO_URL=\"https://github.com/Ludwig-H/PanopticSegForLargeScalePointCloud\"\nif [ ! -d PanopticSegForLargeScalePointCloud ]; then\n  git clone --depth=1 \"$REPO_URL\"\nfi\ncd PanopticSegForLargeScalePointCloud\n# Créer dossiers de données selon README\nmkdir -p data/npm3dfused/raw\nmkdir -p outputs\necho \"Repo ready.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Télécharger NPM3D (avec labels d’instances)\nSource officielle Zenodo `10.5281/zenodo.8118986`. Les fichiers .ply sont posés dans `data/npm3dfused/raw/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\ncd PanopticSegForLargeScalePointCloud/data/npm3dfused/raw\n\nbase=\"https://zenodo.org/records/8118986/files\"\n\nfiles=(\n  \"Paris_train.ply\"\n  \"Paris_val.ply\"\n  \"Paris_test.ply\"\n  \"Lille1_1_train.ply\"\n  \"Lille1_1_val.ply\"\n  \"Lille1_1_test.ply\"\n  \"Lille1_2_train.ply\"\n  \"Lille1_2_val.ply\"\n  \"Lille1_2_test.ply\"\n  \"Lille2_train.ply\"\n  \"Lille2_val.ply\"\n  \"Lille2_test.ply\"\n)\n\nfor f in \"${files[@]}\"; do\n  if [ ! -f \"$f\" ]; then\n    echo \"Downloading $f\"\n    wget -q --show-progress \"${base}/${f}?download=1\" -O \"$f\"\n  else\n    echo \"Already have $f\"\n  fi\ndone\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) (Optionnel) Entraînement NPM3D — même config que le papier\nLes auteurs donnent en exemple Setting **IV** pour `area1`:\n\n```bash\npython train.py task=panoptic \\\n  data=panoptic/npm3d-sparseconv_grid_012_R_16_cylinder_area1 \\\n  models=panoptic/area4_ablation_3heads_5 model_name=PointGroup-PAPER \\\n  training=7_area1 job_name=A1_S7\n```\nTu peux boucler sur `area{1..4}` pour faire le 4-fold.\nMet `WANDB_MODE=offline` pour éviter la synchro en ligne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\ncd PanopticSegForLargeScalePointCloud\n\nexport WANDB_MODE=offline\n# Dé-commenter pour lancer un entraînement complet pour area1 (coûteux).\n# python train.py task=panoptic \\\n#   data=panoptic/npm3d-sparseconv_grid_012_R_16_cylinder_area1 \\\n#   models=panoptic/area4_ablation_3heads_5 model_name=PointGroup-PAPER \\\n#   training=7_area1 job_name=A1_S7\necho \"Entraînement désactivé par défaut (trop long en Colab).\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Extraire les **embeddings 5D** avant clustering\nOn attache un **forward hook** sur la branche d'embedding du modèle pendant l'éval.\nLe script ci-dessous:\n- charge la config Hydra d'éval, le checkpoint, et le dataloader test (mêmes scènes),\n- capture les embeddings par point et les enregistre en `.npz` par bloc.\n\nIl essaie d'abord des clés de sortie usuelles (`embedding`, `embeddings`, `embedding_5d`),\npuis cherche un module dont le nom contient `emb` pour y accrocher un hook si besoin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\ncd PanopticSegForLargeScalePointCloud\n\ncat > tools_extract_embeddings.py << 'PY'\nimport os, sys, glob, json, re, pathlib, numpy as np, torch\nfrom pathlib import Path\nfrom omegaconf import OmegaConf\nsys.path.append(str(Path.cwd()))\n# Import TP3D local copy\nsys.path.append(str(Path.cwd() / \"torch_points3d\"))\nfrom torch_points3d.metrics.panoptic_tracker import PanopticTracker  # noqa: F401 (forces TP3D import)\nfrom train import hydra_main as train_hydra_main  # to reuse config utils if exposed\nfrom eval import hydra_main as eval_hydra_main    # type: ignore\n\n# Small utility to load hydra config from conf/eval.yaml\ndef load_eval_cfg():\n    cfg = OmegaConf.load(\"conf/eval.yaml\")\n    return cfg\n\ndef find_embed_module(model):\n    candidates = []\n    for name, m in model.named_modules():\n        if \"emb\" in name.lower():\n            candidates.append(name)\n    return candidates\n\ndef ensure_dir(p): os.makedirs(p, exist_ok=True)\n\ndef dump_npz(out_dir, tag, data_dict):\n    ensure_dir(out_dir)\n    np.savez_compressed(os.path.join(out_dir, f\"{tag}.npz\"), **data_dict)\n\ndef main():\n    import hydra\n    from omegaconf import DictConfig\n    # Run eval hydra to build model + dataloaders then intercept forward\n    @hydra.main(config_path=\"conf\", config_name=\"eval\", version_base=None)\n    def _run(cfg: DictConfig):\n        # Build model & loaders the same way eval.py does\n        # We call the eval hydra entry but override the evaluation loop to attach hooks.\n        from eval import build_model_and_loaders  # we expect eval.py to expose helpers; fallback otherwise\n        try:\n            model, loaders, device, test_split = build_model_and_loaders(cfg)\n        except Exception as e:\n            print(\"Falling back to importing torch_points3d style builders:\", e)\n            # Fallback: try to import internal builders if authors changed names\n            raise\n\n        model.eval()\n        model = model.to(device)\n\n        # Try to discover an embedding head via outputs or module names\n        caught = {\"batch_indices\": [], \"embeddings\": []}\n        example_name = None\n\n        # Soft hook mechanism\n        chosen_mod = None\n        for name, m in model.named_modules():\n            if re.search(r\"(emb|embed|embedding)\", name, re.I):\n                chosen_mod = m\n                chosen_name = name\n                break\n        hook_handle = None\n        if chosen_mod is not None:\n            def _hook(module, inp, out):\n                # out shape [N, D]\n                try:\n                    E = out.detach().cpu().float().numpy()\n                    caught[\"embeddings\"].append(E)\n                except Exception:\n                    pass\n            hook_handle = chosen_mod.register_forward_hook(lambda m,i,o: _hook(m,i,o))\n            print(f\"[extract] Hooked embedding module: {chosen_name}\", flush=True)\n        else:\n            print(\"[extract] No obvious embedding module found; will try dict outputs.\", flush=True)\n\n        out_root = Path(\"outputs/embeddings\")\n        ensure_dir(out_root)\n\n        # Iterate over test loader only\n        test_loader = loaders.get(test_split, None) or loaders.get(\"test\", None)\n        if test_loader is None:\n            raise RuntimeError(\"Test loader not found in loaders keys:\", loaders.keys())\n\n        with torch.no_grad():\n            for ib, batch in enumerate(test_loader):\n                batch = batch.to(device)\n                out = model(batch)\n                # If model returns dict with embeddings\n                if isinstance(out, dict):\n                    for k in [\"embedding\", \"embeddings\", \"embedding_5d\", \"emb_5d\", \"panoptic_embeddings\"]:\n                        if k in out and isinstance(out[k], torch.Tensor):\n                            E = out[k].detach().cpu().float().numpy()\n                            caught[\"embeddings\"].append(E)\n                            break\n\n                # Gather point indices to map back if available\n                if hasattr(batch, \"idx\"):\n                    idx = batch.idx.detach().cpu().numpy()\n                elif hasattr(batch, \"ptr\"):\n                    idx = batch.ptr.detach().cpu().numpy()\n                else:\n                    # fallback: monotonic indices\n                    n = out[\"semantic\"].shape[0] if isinstance(out, dict) and \"semantic\" in out else 0\n                    idx = np.arange(n, dtype=np.int64)\n\n                # Flatten and dump per-batch\n                if len(caught[\"embeddings\"]) == 0:\n                    print(f\"[extract] WARNING: no embeddings captured for batch {ib}.\")\n                    continue\n                E = caught[\"embeddings\"][-1]\n                tag = f\"batch_{ib:05d}\"\n                dump_npz(out_root, tag, {\"indices\": idx, \"embeddings\": E})\n                print(f\"[extract] Saved embeddings for {tag} -> {E.shape}\", flush=True)\n\n        if hook_handle is not None:\n            hook_handle.remove()\n\n    _run()\n\nif __name__ == \"__main__\":\n    main()\nPY\n\necho \"Script tools_extract_embeddings.py created.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Exécuter l'évaluation et l’extraction d’embeddings\nLe script d’éval officiel produit les dossiers `viz_for_test_*`. Ensuite, on extrait les embeddings en suivant **les mêmes splits/scènes**.\n\n**Remarque:** pense à mettre le chemin du checkpoint (`CKPT_PATH`) si tu n’entraînes pas dans cette session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\ncd PanopticSegForLargeScalePointCloud\n\n# Exemple: on veut évaluer Area 1 (Paris en test) en Setting IV (comme dans README)\n# Si tu as entraîné ici, adapte CKPT_PATH en conséquence; sinon, place un checkpoint existant à l'endroit indiqué.\nCKPT_PATH=\"${CKPT_PATH:-/content/drive/MyDrive/panoptic_runs/A1_S7/checkpoints/best.pth}\" || true\n\n# Adapter conf/eval.yaml avant de lancer eval.py (les auteurs l'indiquent dans le README).\n# Comme on ne connaît pas tes chemins exacts, on te laisse la main:\necho \"Ouvre et adapte conf/eval.yaml si nécessaire (paths, split, ckpt).\"\nsed -n '1,160p' conf/eval.yaml || true\n\n# Lancer l'éval (si eval.py dépend entièrement de conf/eval.yaml)\n# python eval.py\n\n# Ou, si Hydra accepte des overrides, tu peux donner des précisions en CLI (à adapter si besoin) :\n# python eval.py task=panoptic data=panoptic/npm3d-sparseconv_grid_012_R_16_cylinder_area1 \\\n#   models=panoptic/area4_ablation_3heads_5 model_name=PointGroup-PAPER training=7_area1 \\\n#   +eval.ckpt_path=\"$CKPT_PATH\"\n\necho \"Extraction des embeddings (utilise conf/eval.yaml et le même loader test)\"\npython tools_extract_embeddings.py || true\n\necho \"Pour calculer les métriques officielles NPM3D :\"\necho \"python evaluation_stats_NPM3D.py\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Où sont les embeddings et comment brancher ton clusterer\nLes `.npz` sont écrits sous `outputs/embeddings/` avec deux arrays:\n- `embeddings`: matrice `[N, 5]` (D=5 attendu) de l’embedding discriminant par point du batch\n- `indices`: indices des points pour reconstituer l’ordre si besoin\n\n### Exemple: brancher un clusterer perso qui prend soit `X` soit une matrice de distances\nLe snippet ci-dessous charge tous les `.npz`, concatène, normalise à la volée, applique un clusterer,\npuis sauvegarde un `instance_id` par point dans un `.npy`. À toi de remplacer `my_clusterer()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\nimport os, glob, numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\nEMB_DIR = \"PanopticSegForLargeScalePointCloud/outputs/embeddings\"\nOUT_PATH = \"PanopticSegForLargeScalePointCloud/outputs/instance_labels.npy\"\n\ndef load_all_embeddings_npz(emb_dir):\n    files = sorted(glob.glob(os.path.join(emb_dir, \"*.npz\")))\n    Xs, Is = [], []\n    for f in files:\n        d = np.load(f)\n        Xs.append(d[\"embeddings\"])\n        Is.append(d[\"indices\"])\n    if not Xs:\n        raise RuntimeError(\"Aucun fichier d'embedding trouvé dans %s\" % emb_dir)\n    X = np.concatenate(Xs, axis=0)\n    I = np.concatenate(Is, axis=0)\n    return X, I\n\ndef my_clusterer(X):\n    # TODO: remplace par ton algo. Ici, on met un stub trivial à 1 cluster.\n    # X: [N, d]\n    N = X.shape[0]\n    labels = np.zeros(N, dtype=np.int32)\n    return labels\n\nX, I = load_all_embeddings_npz(EMB_DIR)\nXn = StandardScaler().fit_transform(X)\nlabels = my_clusterer(Xn)\nnp.save(OUT_PATH, labels)\nprint(\"Saved instance labels to:\", OUT_PATH, \" shape:\", labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) (Facultatif) Remonter tes clusters en PLY et relancer l’éval officielle\nSi tu veux remplacer les instances du pipeline par les tiennes, convertis `instance_labels.npy` en `.ply` attendu par `evaluation_stats_NPM3D.py`.\nLe format attendu par l’issue #19 indique des champs `pre_sem_label`, `gt_sem_label` et les IDs d’instance prédits/GT. Tu peux partir des sorties de `viz_for_test_valid_proposals` et ne remplacer que la colonne d’instances prédictives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n# Exemple de squelette: à adapter selon les champs déjà présents dans vos PLY de sortie\n# from plyfile import PlyData, PlyElement\n# import numpy as np\n# sem_ply = PlyData.read(\"PanopticSegForLargeScalePointCloud/viz_for_test_valid_proposals/instance.ply\")\n# labels = np.load(\"PanopticSegForLargeScalePointCloud/outputs/instance_labels.npy\")\n# # Construire une nouvelle structure en remplaçant le champ d'instance prédite puis sauvegarder.\n# PlyData([ ... ]).write(\"PanopticSegForLargeScalePointCloud/outputs/instance_custom.ply\")\nprint(\"Voir issue #19 pour les champs consultés par evaluation_stats_NPM3D.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Lancer l’évaluation finale (scripts officiels)\nLes auteurs fournissent `evaluation_stats_NPM3D.py` qui charge les sorties d’éval et calcule F1, PQ, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n%%bash\nset -euxo pipefail\ncd PanopticSegForLargeScalePointCloud\n# Pour NPM3D\npython evaluation_stats_NPM3D.py || true\n# Pour FOR-instance (si utilisé)\n# python evaluation_stats_FOR.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes pratiques\n- Les chemins et le checkpoint à utiliser pour l’éval se règlent dans `conf/eval.yaml` ou via des overrides Hydra. Le README fournit les commandes et les noms des configs pour NPM3D, **Setting IV** notamment.\n- Le dataset NPM3D avec **labels d’instance** se télécharge depuis Zenodo (12 fichiers .ply). On les place sous `data/npm3dfused/raw/` comme indiqué dans le README.\n- Si l’extraction d’embeddings ne capture rien du premier coup, imprime la liste des `model.named_modules()` et choisis un module contenant `emb` pour le hook."
      ]
    }
  ]
}